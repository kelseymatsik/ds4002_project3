{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17b9f9da-87e1-4b03-ad82-2d842b73a9f4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63cd6c34-834e-4a94-91e5-16370998d377",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "base_path = \"/sfs/gpfs/tardis/home/kcm7zp/brain_tumor_data\"\n",
    "\n",
    "tumor_types = ['glioma', 'meningioma', 'pituitary']\n",
    "label_map = {'glioma': 1, 'meningioma': 2, 'pituitary': 3}\n",
    "\n",
    "# print(os.listdir(base_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a96aef1b-07e7-4a57-8847-204e55f32063",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing glioma: 100%|██████████| 1426/1426 [00:09<00:00, 142.71it/s]\n",
      "Processing meningioma: 100%|██████████| 708/708 [00:07<00:00, 88.53it/s] \n",
      "Processing pituitary: 100%|██████████| 930/930 [00:11<00:00, 81.31it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total samples loaded: 3064\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "\n",
    "for tumor in tumor_types:\n",
    "    img_folder = os.path.join(base_path, tumor, \"images\")\n",
    "    mask_folder = os.path.join(base_path, tumor, \"masks\")\n",
    "    \n",
    "    img_files = sorted([f for f in os.listdir(img_folder) if f.endswith(\".png\") and not f.startswith(\".\")])\n",
    "    \n",
    "    for img_file in tqdm(img_files, desc=f\"Processing {tumor}\"):\n",
    "        base_id = img_file.replace(f\"{tumor}_\", \"\").replace(\".png\", \"\")\n",
    "        mask_file = f\"{tumor}_mask_{base_id}.png\"\n",
    "        \n",
    "        img_path = os.path.join(img_folder, img_file)\n",
    "        mask_path = os.path.join(mask_folder, mask_file)\n",
    "        \n",
    "        # Read in the image and mask \n",
    "        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "        mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "        if img is None or mask is None:\n",
    "            print(f\"Failed to load: {img_path} or {mask_path}\")\n",
    "            continue\n",
    "\n",
    "        # Resize to common dimensions\n",
    "        img = cv2.resize(img, (256, 256))\n",
    "        mask = cv2.resize(mask, (256, 256))\n",
    "\n",
    "        # Normalize to [0, 1]\n",
    "        img = img / 255.0\n",
    "        mask = mask / 255.0\n",
    "        \n",
    "        # Append to data list\n",
    "        data.append({\n",
    "            'image': img,\n",
    "            'mask': mask,\n",
    "            'label': label_map[tumor]\n",
    "        })\n",
    "\n",
    "print(f\"\\nTotal samples loaded: {len(data)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7fd9fdac-2e08-495e-ac2e-f172ece9a68d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples loaded: 3064\n",
      "Labels and counts: {1: 1426, 2: 708, 3: 930}\n"
     ]
    }
   ],
   "source": [
    "# Sanity check \n",
    "print(f\"Total samples loaded: {len(data)}\")\n",
    "\n",
    "labels = [item['label'] for item in data]\n",
    "unique_labels, counts = np.unique(labels, return_counts=True)\n",
    "print(\"Labels and counts:\", dict(zip(unique_labels, counts)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "18dbf0b0-51a0-495f-9be4-40a5d7a79348",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Convert to numpy arrays -- run this again\n",
    "# Skip converting masks right now to save memory\n",
    "images = np.array([item['image'] for item in data])\n",
    "# masks = np.array([item['mask'] for item in data])\n",
    "labels = np.array([item['label'] for item in data])\n",
    "\n",
    "# Add channel dimension for Tensorflow/Keras \n",
    "images = np.expand_dims(images, axis=-1)  # shape: (N, 256, 256, 1)\n",
    "# masks = np.expand_dims(masks, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b3810233-80f5-4be4-a782-bb4cc16d7bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/Val/Test Split \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# First split off test\n",
    "X_trainval, X_test, y_trainval, y_test = train_test_split(images, labels, test_size=0.15, stratify=labels, random_state=42)\n",
    "\n",
    "# Then split train and val\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_trainval, y_trainval, test_size=0.15, stratify=y_trainval, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "469f1c8d-43fe-456a-8c4f-df0461d4b03c",
   "metadata": {},
   "source": [
    "## Build the CNN in Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "71da553b-87f6-4cf5-91f2-c471ab1ae404",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-17 11:09:19.542268: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-04-17 11:09:19.736725: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8473] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-04-17 11:09:19.785824: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1471] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-04-17 11:09:20.200972: I tensorflow/core/platform/cpu_feature_guard.cc:211] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE3 SSE4.1 SSE4.2 AVX, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-04-17 11:09:26.047209: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22181 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:c1:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.metrics import Precision, Recall\n",
    "\n",
    "model = models.Sequential([\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(256, 256, 1)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "\n",
    "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(3, activation='softmax')  # 3 tumor classes\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "434a109e-4cf3-4ec2-85e1-18eb5e4a9d9b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Compile the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3a4744d6-5d41-41c2-a45e-b26e1e2e2495",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Shift labels to 0-based indexing (1 --> 0, etc.) \n",
    "y_train = y_train - 1\n",
    "y_val = y_val - 1\n",
    "y_test = y_test - 1\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a8f0fd4-7c70-48ab-81fe-ec3715a5d7fe",
   "metadata": {},
   "source": [
    "## Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c373d9e0-3712-4ef0-9ca0-8a246a4a447c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2]\n",
      "(2213,)\n",
      "[2 1 0 2 2]\n"
     ]
    }
   ],
   "source": [
    "print(np.unique(y_train))     # Should output [0 1 2]\n",
    "print(y_train.shape)          # Should be (N,) — a 1D array\n",
    "print(y_train[:5])            # Check first few labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7b90dfdc-0772-4a72-bc4a-11b2f8780f92",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3064, 256, 256, 1)\n",
      "(3064,)\n",
      "int64\n"
     ]
    }
   ],
   "source": [
    "print(images.shape)           # (3064, 256, 256, 1)\n",
    "print(labels.shape)           # (3064,)\n",
    "print(labels.dtype)           # should be int32 or int64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c3f0c807-acd2-4ec3-94e4-6af4f995d8ee",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/usr/local/lib/python3.12/dist-packages/tf_keras/src/engine/training.py\", line 1398, in train_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.12/dist-packages/tf_keras/src/engine/training.py\", line 1381, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.12/dist-packages/tf_keras/src/engine/training.py\", line 1370, in run_step  **\n        outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.12/dist-packages/tf_keras/src/engine/training.py\", line 1152, in train_step\n        return self.compute_metrics(x, y, y_pred, sample_weight)\n    File \"/usr/local/lib/python3.12/dist-packages/tf_keras/src/engine/training.py\", line 1246, in compute_metrics\n        self.compiled_metrics.update_state(y, y_pred, sample_weight)\n    File \"/usr/local/lib/python3.12/dist-packages/tf_keras/src/engine/compile_utils.py\", line 620, in update_state\n        metric_obj.update_state(y_t, y_p, sample_weight=mask)\n    File \"/usr/local/lib/python3.12/dist-packages/tf_keras/src/utils/metrics_utils.py\", line 77, in decorated\n        result = update_state_fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.12/dist-packages/tf_keras/src/metrics/base_metric.py\", line 140, in update_state_fn\n        return ag_update_state(*args, **kwargs)\n    File \"/usr/local/lib/python3.12/dist-packages/tf_keras/src/metrics/confusion_metrics.py\", line 470, in update_state  **\n        return metrics_utils.update_confusion_matrix_variables(\n    File \"/usr/local/lib/python3.12/dist-packages/tf_keras/src/utils/metrics_utils.py\", line 672, in update_confusion_matrix_variables\n        y_pred.shape.assert_is_compatible_with(y_true.shape)\n\n    ValueError: Shapes (None, 3) and (None, 1) are incompatible\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Hide warnings \u001b[39;00m\n\u001b[1;32m      2\u001b[0m warnings\u001b[38;5;241m.\u001b[39mfilterwarnings(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.12/dist-packages/tf_keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/tmp/__autograph_generated_filemz0lcnqo.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/usr/local/lib/python3.12/dist-packages/tf_keras/src/engine/training.py\", line 1398, in train_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.12/dist-packages/tf_keras/src/engine/training.py\", line 1381, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.12/dist-packages/tf_keras/src/engine/training.py\", line 1370, in run_step  **\n        outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.12/dist-packages/tf_keras/src/engine/training.py\", line 1152, in train_step\n        return self.compute_metrics(x, y, y_pred, sample_weight)\n    File \"/usr/local/lib/python3.12/dist-packages/tf_keras/src/engine/training.py\", line 1246, in compute_metrics\n        self.compiled_metrics.update_state(y, y_pred, sample_weight)\n    File \"/usr/local/lib/python3.12/dist-packages/tf_keras/src/engine/compile_utils.py\", line 620, in update_state\n        metric_obj.update_state(y_t, y_p, sample_weight=mask)\n    File \"/usr/local/lib/python3.12/dist-packages/tf_keras/src/utils/metrics_utils.py\", line 77, in decorated\n        result = update_state_fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.12/dist-packages/tf_keras/src/metrics/base_metric.py\", line 140, in update_state_fn\n        return ag_update_state(*args, **kwargs)\n    File \"/usr/local/lib/python3.12/dist-packages/tf_keras/src/metrics/confusion_metrics.py\", line 470, in update_state  **\n        return metrics_utils.update_confusion_matrix_variables(\n    File \"/usr/local/lib/python3.12/dist-packages/tf_keras/src/utils/metrics_utils.py\", line 672, in update_confusion_matrix_variables\n        y_pred.shape.assert_is_compatible_with(y_true.shape)\n\n    ValueError: Shapes (None, 3) and (None, 1) are incompatible\n"
     ]
    }
   ],
   "source": [
    "# Hide warnings \n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=10,\n",
    "    batch_size=32,\n",
    "    validation_data=(X_val, y_val)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5275f55-8586-4d46-b9ad-7160e11c1857",
   "metadata": {},
   "source": [
    "## Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e75111-6c01-4630-9928-571fd73731c3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "print(f\"\\nTest Accuracy: {test_acc:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tensorflow 2.17.0",
   "language": "python",
   "name": "tensorflow-2.17.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
